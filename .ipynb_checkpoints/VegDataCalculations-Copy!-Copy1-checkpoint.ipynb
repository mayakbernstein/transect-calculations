{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c19ed2-e2b5-40c3-96b0-b5058150b780",
   "metadata": {},
   "source": [
    "# **Line Intercept Vegetation Calculations**\n",
    "\n",
    "**this notebook contains code for calculations of percent cover of various cover types across:**\n",
    "1. The entire transect (to HTS)\n",
    "2. the foredune portion of the transect (dune heel to dune toe)\n",
    "3. the vegetated portion of the transect (to lowest veg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3aa90-e49d-4b0a-93dc-cd9fb2557ae5",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbb9085-a06e-44a5-afd9-7c7f7f32399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc470de8-ec67-40dc-9522-60f1f101381e",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "replace the file_path within the parentheses '' with the actual path to your excel file containing the raw data. \n",
    "\n",
    "Note: Your excel data must be formatted according to the following sheet to work with the rest of the code:\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1tFZVjsOSf4BBCrjyVIJQeS-zN7qWJvLR3fg2mDO5wUA/edit?usp=sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef20b273-1ed7-4cdc-bfef-04c095b62c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path\n",
    "file_path = '/Users/mayabernstein/Documents/SeaGrantVeg/combined_data.xlsx' #replace with your file path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b9f51-3366-4e82-8388-faaf4dd05b3d",
   "metadata": {},
   "source": [
    "## Load Data From Each Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea8753d-714d-43d8-ac3f-39fdb9c24d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_df = pd.read_excel(file_path, sheet_name=\"PositionalCharacteristics\")\n",
    "transects_df = pd.read_excel(file_path, sheet_name=\"Transects\")\n",
    "elevation_df = pd.read_excel(file_path, sheet_name=\"Elevation\")\n",
    "readme_df = pd.read_excel(file_path, sheet_name=\"ReadMe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9c4cd-e6d9-44ed-b948-9496739a2c22",
   "metadata": {},
   "source": [
    "## Create a Dataframe\n",
    "\n",
    "This will be where the calculated variables are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e83d3d-6e7a-494b-b9e3-fce1a3d15a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculations_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c115b-0a82-4353-b7fc-aca20cdba473",
   "metadata": {},
   "source": [
    "## Supplement Transect Data\n",
    "\n",
    "This adds new columns to identify if the rows are:\n",
    "1. vegetation \n",
    "2. within the foredune\n",
    "3. within the vegetated portion of the tranesct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2005259f-d73f-4e3a-8091-5b38b715bfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       transect  start    end  type  depth  pct_cover  \\\n",
      "0        EastBeach_01-19-2024_A   0.00   0.04  DISP    6.0      100.0   \n",
      "1        EastBeach_01-19-2024_A   0.04   4.47  MEXX    5.0        1.0   \n",
      "2        EastBeach_01-19-2024_A   0.04   4.47  SPMA    3.0       20.0   \n",
      "3        EastBeach_01-19-2024_A   0.04   4.47  CYDA    4.0        4.0   \n",
      "4        EastBeach_01-19-2024_A   0.04   4.47  DISP    5.0        1.0   \n",
      "...                         ...    ...    ...   ...    ...        ...   \n",
      "3010  CoalOilPoint_09-27-2023_D  34.20  34.30     M    4.0       50.0   \n",
      "3011  CoalOilPoint_09-27-2023_D  34.80  34.93     P    2.0       60.0   \n",
      "3012  CoalOilPoint_09-27-2023_D  50.00  50.15     M    1.0      100.0   \n",
      "3013  CoalOilPoint_09-27-2023_D  50.15  50.21     P    1.0      100.0   \n",
      "3014  CoalOilPoint_09-27-2023_D  56.00  56.20     M    3.0      100.0   \n",
      "\n",
      "      total_length  cor_length      sitename        date  \\\n",
      "0             0.04      0.0400     EastBeach  01-19-2024   \n",
      "1             4.43      0.0443     EastBeach  01-19-2024   \n",
      "2             4.43      0.8860     EastBeach  01-19-2024   \n",
      "3             4.43      0.1772     EastBeach  01-19-2024   \n",
      "4             4.43      0.0443     EastBeach  01-19-2024   \n",
      "...            ...         ...           ...         ...   \n",
      "3010          0.10      0.0500  CoalOilPoint  09-27-2023   \n",
      "3011          0.13      0.0780  CoalOilPoint  09-27-2023   \n",
      "3012          0.15      0.1500  CoalOilPoint  09-27-2023   \n",
      "3013          0.06      0.0600  CoalOilPoint  09-27-2023   \n",
      "3014          0.20      0.2000  CoalOilPoint  09-27-2023   \n",
      "\n",
      "                                            transectkey  native  vegetation  \\\n",
      "0           EastBeach_01-19-2024_EastBeach_01-19-2024_A     1.0        True   \n",
      "1           EastBeach_01-19-2024_EastBeach_01-19-2024_A     0.0        True   \n",
      "2           EastBeach_01-19-2024_EastBeach_01-19-2024_A     1.0        True   \n",
      "3           EastBeach_01-19-2024_EastBeach_01-19-2024_A     0.0        True   \n",
      "4           EastBeach_01-19-2024_EastBeach_01-19-2024_A     1.0        True   \n",
      "...                                                 ...     ...         ...   \n",
      "3010  CoalOilPoint_09-27-2023_CoalOilPoint_09-27-2023_D     1.0       False   \n",
      "3011  CoalOilPoint_09-27-2023_CoalOilPoint_09-27-2023_D     1.0       False   \n",
      "3012  CoalOilPoint_09-27-2023_CoalOilPoint_09-27-2023_D     1.0       False   \n",
      "3013  CoalOilPoint_09-27-2023_CoalOilPoint_09-27-2023_D     1.0       False   \n",
      "3014  CoalOilPoint_09-27-2023_CoalOilPoint_09-27-2023_D     1.0       False   \n",
      "\n",
      "      toe_sea  toe_in  lowest_veg  start_within_dune  end_within_dune   dune  \\\n",
      "0        50.0     0.0        51.0               True             True   True   \n",
      "1        50.0     0.0        51.0               True             True   True   \n",
      "2        50.0     0.0        51.0               True             True   True   \n",
      "3        50.0     0.0        51.0               True             True   True   \n",
      "4        50.0     0.0        51.0               True             True   True   \n",
      "...       ...     ...         ...                ...              ...    ...   \n",
      "3010     34.0     0.0        32.0              False            False  False   \n",
      "3011     34.0     0.0        32.0              False            False  False   \n",
      "3012     34.0     0.0        32.0              False            False  False   \n",
      "3013     34.0     0.0        32.0              False            False  False   \n",
      "3014     34.0     0.0        32.0              False            False  False   \n",
      "\n",
      "        veg  \n",
      "0      True  \n",
      "1      True  \n",
      "2      True  \n",
      "3      True  \n",
      "4      True  \n",
      "...     ...  \n",
      "3010  False  \n",
      "3011  False  \n",
      "3012  False  \n",
      "3013  False  \n",
      "3014  False  \n",
      "\n",
      "[3015 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Strip leading/trailing spaces to ensure clean matching\n",
    "transects_df['type'] = transects_df['type'].str.strip()\n",
    "readme_df['name'] = readme_df['name'].str.strip()\n",
    "\n",
    "#amend the transects column to have more specific data so there are no duplicate values\n",
    "transects_df[\"transect\"] = transects_df[\"sitename\"] + \"_\" + transects_df[\"date\"].astype(str) + \"_\" + transects_df[\"transect\"]\n",
    "positional_df[\"transect\"] = positional_df[\"sitename\"] + \"_\" + positional_df[\"date\"].astype(str) + \"_\" + positional_df[\"transect\"]\n",
    "\n",
    "# **Create 'transectkey' in transects_df**\n",
    "transects_df[\"transectkey\"] = transects_df[\"sitename\"] + \"_\" + transects_df[\"date\"].astype(str) + \"_\" + transects_df[\"transect\"]\n",
    "\n",
    "# Create 'transectkey' in positional_df\n",
    "positional_df[\"transectkey\"] = positional_df[\"sitename\"] + \"_\" + positional_df[\"date\"].astype(str) + \"_\" + positional_df[\"transect\"]\n",
    "\n",
    "calculations_df[\"transectkey\"] = transects_df[\"transect\"] # Consider if you need this\n",
    "\n",
    "# Create a mapping from 'name' to 'native' from readme_df\n",
    "name_to_native = readme_df.set_index('name')['native']\n",
    "\n",
    "# Add 'native' column to transects_df based on 'type' matching 'name'\n",
    "transects_df['native'] = transects_df['type'].map(name_to_native)\n",
    "\n",
    "# Add a new column indicating if 'type' is vegetation (4 or 5 characters long)\n",
    "transects_df['vegetation'] = transects_df['type'].str.len().isin([4, 5])\n",
    "\n",
    "# Create a mapping for positional information (toe_sea, toe_in, lowest_veg)\n",
    "positional_mapping = positional_df.set_index('transectkey')[['toe_sea', 'toe_in', 'lowest_veg']]\n",
    "\n",
    "# Map the positional values to transects_df\n",
    "transects_df = transects_df.join(positional_mapping, on='transectkey')\n",
    "\n",
    "# Identify if the start and end positions are within the dune\n",
    "transects_df['start_within_dune'] = (transects_df['start'] <= transects_df['toe_sea']) & (transects_df['start'] >= transects_df['toe_in'])\n",
    "transects_df['end_within_dune'] = (transects_df['end'] >= transects_df['toe_in']) & (transects_df['end'] <= transects_df['toe_sea'])\n",
    "\n",
    "# Create the final 'dune' column by checking if either start or end is within the dune\n",
    "transects_df['dune'] = transects_df['start_within_dune'] | transects_df['end_within_dune']\n",
    "\n",
    "# Identify if the row is within the vegetated portion of the dune\n",
    "transects_df['veg'] = transects_df['start'] <= transects_df['lowest_veg']\n",
    "\n",
    "print(transects_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca013abe-3805-499f-ad65-a888f46fec49",
   "metadata": {},
   "source": [
    "## Calculate and build in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9300f1-a448-4d23-b5a7-2f16ef3f40a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    transectkey                transect  tran_length  \\\n",
      "0        EastBeach_01-19-2024_A  EastBeach_01-19-2024_A         74.0   \n",
      "1        EastBeach_01-19-2024_A  EastBeach_01-19-2024_B         70.0   \n",
      "2        EastBeach_01-19-2024_A  EastBeach_01-19-2024_C         76.0   \n",
      "3        EastBeach_01-19-2024_A    EastDep_07-26-2023_A         45.4   \n",
      "4        EastBeach_01-19-2024_A    EastDep_07-26-2023_B         37.0   \n",
      "...                         ...                     ...          ...   \n",
      "3010  CoalOilPoint_09-27-2023_D                     NaN          NaN   \n",
      "3011  CoalOilPoint_09-27-2023_D                     NaN          NaN   \n",
      "3012  CoalOilPoint_09-27-2023_D                     NaN          NaN   \n",
      "3013  CoalOilPoint_09-27-2023_D                     NaN          NaN   \n",
      "3014  CoalOilPoint_09-27-2023_D                     NaN          NaN   \n",
      "\n",
      "      dune_length  veg_length  cor_length  pctcov_all_whole  \n",
      "0            50.0       51.00         NaN               NaN  \n",
      "1            53.0       53.00         NaN               NaN  \n",
      "2            53.0       55.04         NaN               NaN  \n",
      "3            16.5       21.40         NaN               NaN  \n",
      "4             7.7        7.70         NaN               NaN  \n",
      "...           ...         ...         ...               ...  \n",
      "3010          NaN         NaN         NaN               NaN  \n",
      "3011          NaN         NaN         NaN               NaN  \n",
      "3012          NaN         NaN         NaN               NaN  \n",
      "3013          NaN         NaN         NaN               NaN  \n",
      "3014          NaN         NaN         NaN               NaN  \n",
      "\n",
      "[3015 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#transect letter\n",
    "calculations_df[\"transect\"] = positional_df[\"transect\"]\n",
    "\n",
    "# transect length\n",
    "calculations_df[\"tran_length\"] = positional_df[\"HTS\"]  \n",
    "\n",
    "# dune length\n",
    "dune_length = positional_df[\"toe_sea\"] - positional_df[\"toe_in\"]\n",
    "calculations_df[\"dune_length\"] = dune_length\n",
    "\n",
    "#vegeted length\n",
    "calculations_df[\"veg_length\"] = positional_df[\"lowest_veg\"]  \n",
    "\n",
    "#-------TRANECT WIDE------\n",
    "\n",
    "# Sum 'cor_length' for each transect key\n",
    "pct_cover_all_whole = transects_df.groupby(\"transectkey\")[\"cor_length\"].sum().reset_index()\n",
    "\n",
    "# Merge with 'calculations_df' to ensure matching transect keys\n",
    "calculations_df = calculations_df.merge(pct_cover_all_whole, on=\"transectkey\", how=\"left\")\n",
    "\n",
    "# Divide by 'tran_length' column in calculations_df\n",
    "calculations_df[\"pctcov_all_whole\"] = calculations_df[\"cor_length\"] / calculations_df[\"tran_length\"]\n",
    "\n",
    "# Drop the extra 'cor_length' column if no longer needed\n",
    "#calculations_df.drop(columns=[\"cor_length\"], inplace=True)\n",
    "\n",
    "print(calculations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21855cd-7c69-41b7-881b-6b54ff000975",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ------- TRANSECT-WIDE ---------\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#---- percent cover of everything over entire transect length\u001b[39;00m\n\u001b[1;32m     17\u001b[0m pct_cover_all_whole \u001b[38;5;241m=\u001b[39m transects_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransectkey\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcor_length\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m calculations_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransectkey\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtran_length\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m calculations_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpctcov_all_whole\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcalculations_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransectkey\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpct_cover_all_whole\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#----- veg over whole transect\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Filter the rows where 'type' contains a four or five letter code\u001b[39;00m\n\u001b[1;32m     23\u001b[0m vegetation_df \u001b[38;5;241m=\u001b[39m transects_df[transects_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlen()\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m])]\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/series.py:4700\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[1;32m   4621\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4622\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   4623\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4624\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4626\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4627\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4698\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4699\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4700\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4702\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4703\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/algorithms.py:1732\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1728\u001b[0m     mapper \u001b[38;5;241m=\u001b[39m mapper[mapper\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnotna()]\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# Since values were input this means we came from either\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# a dict or a series and mapper should be an index\u001b[39;00m\n\u001b[0;32m-> 1732\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m new_values \u001b[38;5;241m=\u001b[39m take_nd(mapper\u001b[38;5;241m.\u001b[39m_values, indexer)\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/indexes/base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "#transect letter\n",
    "calculations_df[\"transect\"] = positional_df[\"transect\"]\n",
    "\n",
    "# transect length\n",
    "calculations_df[\"tran_length\"] = positional_df[\"HTS\"]  \n",
    "\n",
    "# dune length\n",
    "dune_length = positional_df[\"toe_sea\"] - positional_df[\"toe_in\"]\n",
    "calculations_df[\"dune_length\"] = dune_length\n",
    "\n",
    "#vegeted length\n",
    "calculations_df[\"veg_length\"] = positional_df[\"lowest_veg\"]  \n",
    "\n",
    "# ------- TRANSECT-WIDE ---------\n",
    "\n",
    "#---- percent cover of everything over entire transect length\n",
    "pct_cover_all_whole = transects_df.groupby(\"transectkey\")[\"cor_length\"].sum() / calculations_df.set_index(\"transectkey\")[\"tran_length\"]\n",
    "calculations_df[\"pctcov_all_whole\"] = calculations_df[\"transectkey\"].map(pct_cover_all_whole)\n",
    "\n",
    "#----- veg over whole transect\n",
    "\n",
    "# Filter the rows where 'type' contains a four or five letter code\n",
    "vegetation_df = transects_df[transects_df['type'].str.len().isin([4, 5])]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "veg_cover_sum = vegetation_df.groupby(\"transectkey\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of vegetation over the entire transect\n",
    "pct_cover_veg_whole = veg_cover_sum / calculations_df.set_index(\"transectkey\")[\"tran_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_veg_whole\"] = calculations_df[\"transectkey\"].map(pct_cover_veg_whole)\n",
    "\n",
    "#----- native veg whole transect\n",
    "\n",
    "# Filter the rows where 'type' contains a four or five letter code and 'native' is 1.0\n",
    "native_vegetation_df = transects_df[(transects_df['type'].str.len().isin([4, 5])) & (transects_df['native'] == 1.0)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "native_veg_cover_sum = native_vegetation_df.groupby(\"transectkey\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of native vegetation over the entire transect\n",
    "pct_cover_native_veg_whole = native_veg_cover_sum / calculations_df.set_index(\"transectkey\")[\"tran_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_native_whole\"] = calculations_df[\"transectkey\"].map(pct_cover_native_veg_whole)\n",
    "\n",
    "#----- nonnative veg whole transect\n",
    "\n",
    "# Filter the rows where 'type' contains a four or five letter code and 'native' is 0.0\n",
    "non_native_vegetation_df = transects_df[(transects_df['type'].str.len().isin([4, 5])) & (transects_df['native'] == 0.0)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "non_native_veg_cover_sum = non_native_vegetation_df.groupby(\"transectkey\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of non-native vegetation over the entire transect\n",
    "pct_cover_non_native_veg_whole = non_native_veg_cover_sum / calculations_df.set_index(\"transectkey\")[\"tran_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_nonnative_whole\"] = calculations_df[\"transectkey\"].map(pct_cover_non_native_veg_whole)\n",
    "\n",
    "# ------- FOREDUNE --------------\n",
    "\n",
    "#------- all cover along dune\n",
    "\n",
    "# Filter for rows where 'dune' is True\n",
    "dune_df = transects_df[transects_df[\"dune\"] == True]\n",
    "\n",
    "# Sum the 'cor_length' for each transect\n",
    "dune_cover_sum = dune_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover by dividing by 'dune_length' from calculations_df\n",
    "pct_cover_dune = dune_cover_sum / calculations_df.set_index(\"transect\")[\"dune_length\"]\n",
    "\n",
    "# Add this calculation to calculations_df\n",
    "calculations_df[\"pctcov_all_dune\"] = calculations_df[\"transect\"].map(pct_cover_dune)\n",
    "\n",
    "#----- veg cover dune\n",
    "\n",
    "# Filter for rows where both 'vegetation' and 'dune' are True\n",
    "dune_vegetation_df = transects_df[(transects_df[\"vegetation\"] == True) & (transects_df[\"dune\"] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for each transect for only vegetation in the dune portion\n",
    "veg_cover_dune_sum = dune_vegetation_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover by dividing by 'dune_length' from calculations_df\n",
    "pct_cover_veg_dune = veg_cover_dune_sum / calculations_df.set_index(\"transect\")[\"dune_length\"]\n",
    "\n",
    "# Add this calculation to calculations_df\n",
    "calculations_df[\"pctcov_veg_dune\"] = calculations_df[\"transect\"].map(pct_cover_veg_dune)\n",
    "\n",
    "# ------ native cover dune\n",
    "# Filter for rows where 'vegetation' is True, 'dune' is True, and 'native' is 1.0\n",
    "native_dune_veg_df = transects_df[(transects_df[\"vegetation\"] == True) & \n",
    "                                  (transects_df[\"dune\"] == True) & \n",
    "                                  (transects_df[\"native\"] == 1.0)]\n",
    "\n",
    "# Sum the 'cor_length' for each transect for only native vegetation in the dune portion\n",
    "native_veg_cover_dune_sum = native_dune_veg_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover by dividing by 'dune_length' from calculations_df\n",
    "pct_cover_native_veg_dune = native_veg_cover_dune_sum / calculations_df.set_index(\"transect\")[\"dune_length\"]\n",
    "\n",
    "# Add this calculation to calculations_df\n",
    "calculations_df[\"pctcov_native_dune\"] = calculations_df[\"transect\"].map(pct_cover_native_veg_dune)\n",
    "\n",
    "# ------ nonnative cover dune\n",
    "# Filter for rows where 'vegetation' is True, 'dune' is True, and 'native' is 0.0 (nonnative)\n",
    "nonnative_dune_veg_df = transects_df[(transects_df[\"vegetation\"] == True) & \n",
    "                                  (transects_df[\"dune\"] == True) & \n",
    "                                  (transects_df[\"native\"] == 0.0)]\n",
    "\n",
    "# Sum the 'cor_length' for each transect for only native vegetation in the dune portion\n",
    "nonnative_veg_cover_dune_sum = nonnative_dune_veg_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover by dividing by 'dune_length' from calculations_df\n",
    "pct_cover_nonnative_veg_dune = nonnative_veg_cover_dune_sum / calculations_df.set_index(\"transect\")[\"dune_length\"]\n",
    "\n",
    "# Add this calculation to calculations_df\n",
    "calculations_df[\"pctcov_nonnative_dune\"] = calculations_df[\"transect\"].map(pct_cover_nonnative_veg_dune)\n",
    "\n",
    "#---------VEGETATED PORTION-----------\n",
    "\n",
    "#------- all cover along veg\n",
    "\n",
    "# Filter for rows where 'veg' is True\n",
    "veg_df = transects_df[transects_df[\"veg\"] == True]\n",
    "\n",
    "# Sum the 'cor_length' for each transect\n",
    "veg_cover_sum = veg_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover by dividing by 'veg_length' from calculations_df\n",
    "pct_cover_veg = veg_cover_sum / calculations_df.set_index(\"transect\")[\"veg_length\"]\n",
    "\n",
    "# Add this calculation to calculations_df\n",
    "calculations_df[\"pctcov_all_veg\"] = calculations_df[\"transect\"].map(pct_cover_veg)\n",
    "\n",
    "#----- veg cover veg\n",
    "\n",
    "# Filter for rows where both 'vegetation' and 'veg' are True\n",
    "veg_vegetation_df = transects_df[(transects_df[\"vegetation\"] == True) & (transects_df[\"veg\"] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for each transect for only vegetation in the veg portion\n",
    "veg_cover_veg_sum = veg_vegetation_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover by dividing by 'veg_length' from calculations_df\n",
    "pct_cover_veg_veg = veg_cover_veg_sum / calculations_df.set_index(\"transect\")[\"veg_length\"]\n",
    "\n",
    "# Add this calculation to calculations_df\n",
    "calculations_df[\"pctcov_veg_veg\"] = calculations_df[\"transect\"].map(pct_cover_veg_veg)\n",
    "\n",
    "# ------ native cover veg\n",
    "# Filter for rows where 'vegetation' is True, 'veg' is True, and 'native' is 1.0\n",
    "native_veg_veg_df = transects_df[(transects_df[\"vegetation\"] == True) & \n",
    "                                  (transects_df[\"veg\"] == True) & \n",
    "                                  (transects_df[\"native\"] == 1.0)]\n",
    "\n",
    "# Sum the 'cor_length' for each transect for only native vegetation in the veg portion\n",
    "native_veg_cover_veg_sum = native_veg_veg_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover by dividing by 'veg_length' from calculations_df\n",
    "pct_cover_native_veg_veg = native_veg_cover_veg_sum / calculations_df.set_index(\"transect\")[\"veg_length\"]\n",
    "\n",
    "# Add this calculation to calculations_df\n",
    "calculations_df[\"pctcov_native_veg\"] = calculations_df[\"transect\"].map(pct_cover_native_veg_veg)\n",
    "\n",
    "# ------ nonnative cover veg\n",
    "# Filter for rows where 'vegetation' is True, 'veg' is True, and 'native' is 0.0 (nonnative)\n",
    "nonnative_veg_veg_df = transects_df[(transects_df[\"vegetation\"] == True) & \n",
    "                                  (transects_df[\"veg\"] == True) & \n",
    "                                  (transects_df[\"native\"] == 0.0)]\n",
    "\n",
    "# Sum the 'cor_length' for each transect for only native vegetation in the veg portion\n",
    "nonnative_veg_cover_veg_sum = nonnative_veg_veg_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover by dividing by 'veg_length' from calculations_df\n",
    "pct_cover_nonnative_veg_veg = nonnative_veg_cover_veg_sum / calculations_df.set_index(\"transect\")[\"veg_length\"]\n",
    "\n",
    "# Add this calculation to calculations_df\n",
    "calculations_df[\"pctcov_nonnative_veg\"] = calculations_df[\"transect\"].map(pct_cover_nonnative_veg_veg)\n",
    "\n",
    "#------------species specific-----------------\n",
    "\n",
    "\n",
    "#species over whole transect\n",
    "\n",
    "#abma whole \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'ABMA'\n",
    "abma_vegetation_df = transects_df[transects_df['type'] == 'ABMA']\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "abma_cover_sum = abma_vegetation_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of ABMA over the entire transect\n",
    "pct_cover_abma_whole = abma_cover_sum / calculations_df.set_index(\"transect\")[\"tran_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_abma_whole\"] = calculations_df[\"transect\"].map(pct_cover_abma_whole)\n",
    "\n",
    "# amch whole \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'ABMA'\n",
    "amch_vegetation_df = transects_df[transects_df['type'] == 'AMCH']\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "amch_cover_sum = amch_vegetation_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of AMCH over the entire transect\n",
    "pct_cover_amch_whole = amch_cover_sum / calculations_df.set_index(\"transect\")[\"tran_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_amch_whole\"] = calculations_df[\"transect\"].map(pct_cover_amch_whole)\n",
    "\n",
    "# cach whole\n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'CACH'\n",
    "cach_vegetation_df = transects_df[transects_df['type'] == 'CACH']\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "cach_cover_sum = cach_vegetation_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of CACH over the entire transect\n",
    "pct_cover_cach_whole = cach_cover_sum / calculations_df.set_index(\"transect\")[\"tran_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_cach_whole\"] = calculations_df[\"transect\"].map(pct_cover_cach_whole)\n",
    "\n",
    "#atle whole\n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'ATLE'\n",
    "atle_vegetation_df = transects_df[transects_df['type'] == 'ATLE']\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "atle_cover_sum = atle_vegetation_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of ATLE over the entire transect\n",
    "pct_cover_atle_whole = atle_cover_sum / calculations_df.set_index(\"transect\")[\"tran_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_atle_whole\"] = calculations_df[\"transect\"].map(pct_cover_atle_whole)\n",
    "\n",
    "# species over dune\n",
    "\n",
    "#abma dune \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'ABMA' and the 'dune' column is True\n",
    "abma_vegetation_dune_df = transects_df[(transects_df['type'] == 'ABMA') & (transects_df['dune'] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "abma_cover_sum_dune = abma_vegetation_dune_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of ABMA over the dune portion of the transect\n",
    "pct_cover_abma_dune = abma_cover_sum_dune / calculations_df.set_index(\"transect\")[\"dune_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_abma_dune\"] = calculations_df[\"transect\"].map(pct_cover_abma_dune)\n",
    "\n",
    "#amch dune \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'AMCH' and the 'dune' column is True\n",
    "amch_vegetation_dune_df = transects_df[(transects_df['type'] == 'AMCH') & (transects_df['dune'] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "amch_cover_sum_dune = amch_vegetation_dune_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of AMCH over the dune portion of the transect\n",
    "pct_cover_amch_dune = amch_cover_sum_dune / calculations_df.set_index(\"transect\")[\"dune_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_amch_dune\"] = calculations_df[\"transect\"].map(pct_cover_amch_dune)\n",
    "\n",
    "#cach dune \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'CACH' and the 'dune' column is True\n",
    "cach_vegetation_dune_df = transects_df[(transects_df['type'] == 'CACH') & (transects_df['dune'] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "cach_cover_sum_dune = cach_vegetation_dune_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of CACH over the dune portion of the transect\n",
    "pct_cover_cach_dune = cach_cover_sum_dune / calculations_df.set_index(\"transect\")[\"dune_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_cach_dune\"] = calculations_df[\"transect\"].map(pct_cover_cach_dune)\n",
    "\n",
    "#atle dune \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'ATLE' and the 'dune' column is True\n",
    "atle_vegetation_dune_df = transects_df[(transects_df['type'] == 'ATLE') & (transects_df['dune'] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "atle_cover_sum_dune = atle_vegetation_dune_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of ATLE over the dune portion of the transect\n",
    "pct_cover_atle_dune = atle_cover_sum_dune / calculations_df.set_index(\"transect\")[\"dune_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_atle_dune\"] = calculations_df[\"transect\"].map(pct_cover_atle_dune)\n",
    "\n",
    "#species over veg poriton \n",
    "\n",
    "#abma veg \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'ABMA' and the 'veg' column is True\n",
    "abma_vegetation_veg_df = transects_df[(transects_df['type'] == 'ABMA') & (transects_df['veg'] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "abma_cover_sum_veg = abma_vegetation_veg_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of ABMA over the veg portion of the transect\n",
    "pct_cover_abma_veg = abma_cover_sum_veg / calculations_df.set_index(\"transect\")[\"veg_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_abma_veg\"] = calculations_df[\"transect\"].map(pct_cover_abma_veg)\n",
    "\n",
    "#amch veg \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'AMCH' and the 'veg' column is True\n",
    "amch_vegetation_veg_df = transects_df[(transects_df['type'] == 'AMCH') & (transects_df['veg'] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "amch_cover_sum_veg = amch_vegetation_veg_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of AMCH over the veg portion of the transect\n",
    "pct_cover_amch_veg = amch_cover_sum_veg / calculations_df.set_index(\"transect\")[\"veg_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_amch_veg\"] = calculations_df[\"transect\"].map(pct_cover_amch_veg)\n",
    "\n",
    "#cach veg \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'CACH' and the 'veg' column is True\n",
    "cach_vegetation_veg_df = transects_df[(transects_df['type'] == 'CACH') & (transects_df['veg'] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "cach_cover_sum_veg = cach_vegetation_veg_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of CACH over the veg portion of the transect\n",
    "pct_cover_cach_veg = cach_cover_sum_veg / calculations_df.set_index(\"transect\")[\"veg_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_cach_veg\"] = calculations_df[\"transect\"].map(pct_cover_cach_veg)\n",
    "\n",
    "#atle veg \n",
    "\n",
    "# Filter the transects_df for rows where the 'type' is 'ATLE' and the 'veg' column is True\n",
    "atle_vegetation_veg_df = transects_df[(transects_df['type'] == 'ATLE') & (transects_df['veg'] == True)]\n",
    "\n",
    "# Sum the 'cor_length' for those rows\n",
    "atle_cover_sum_veg = atle_vegetation_veg_df.groupby(\"transect\")[\"cor_length\"].sum()\n",
    "\n",
    "# Calculate the percent cover of ATLE over the veg portion of the transect\n",
    "pct_cover_atle_veg = atle_cover_sum_veg / calculations_df.set_index(\"transect\")[\"veg_length\"]\n",
    "\n",
    "# Add this calculation to the 'calculations_df'\n",
    "calculations_df[\"pctcov_atle_veg\"] = calculations_df[\"transect\"].map(pct_cover_atle_veg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97d92ea-ed85-4dfd-b470-ee6bea0460e8",
   "metadata": {},
   "source": [
    "## Check Dataframes\n",
    "This part of the code is optional. Just print the dataframes to see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db9b26-efcf-41cf-bdfe-b8020ce29c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda0ef5-d28b-4ea5-956f-5fc90e4def2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transects_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f5e11-8994-4308-b155-387bace3b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positional_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49e4b9-c4ab-4559-9f0a-61bba5357187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
